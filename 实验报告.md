markdown
复制代码
# <center>社会计算实验报告</center>

## 摘要
在这一部分，简要介绍论文的主题、主要研究内容以及实验结果的概览。

## 引言
在这一部分，介绍研究的背景和论文的主要目标和动机。

## 研究背景
FinBERT 论文专注于金融领域的情感分析，这是因为金融语言具有高度专业性，且相关的标记数据相对稀缺。尽管传统的情感分析模型在通用文本上表现良好，但在处理充满专业术语的金融文本时常常力不从心。随着金融文本量的日益增长，人工分析变得不切实际，这增加了对高效自动化分析工具的需求。在此背景下，FinBERT通过预训练的BERT模型，并在金融特定数据上进行微调，有效提升了对金融情感的分析准确性。<br>
基于FinBERT的成功，我们小组提出了将循环卷积神经网络（RCNN）与对抗训练相结合的新模型——FinBERT-RCNN。RCNN结合了循环神经网络(RNN)和卷积神经网络(CNN)的优势，优化了文本数据的深层次语义特征提取。通过引入对抗训练，我们旨在增强模型在面对金融文本中复杂情绪表达时的鲁棒性和泛化能力。


## 研究意义
本次研究通过创新地结合RCNN架构和对抗训练技术，显著优化了金融领域的情感分析工具。这种方法不仅提高了情感分析的精度，还增强了模型对金融市场情绪波动的适应性和敏感性。FinBERT-RCNN的开发标志着金融情感分析向更高精度和复杂情境适应性的进步，同时验证了混合神经网络模型处理特定领域问题的有效性。此外，对抗训练的引入为模型提供了额外的稳定性，使其在实际金融应用中更为可靠。<br>
本次研究为金融情感分析领域带来了新的研究方向和实际应用的可能性，有望更准确地预测市场对金融新闻的反应，从而为金融决策提供科学依据。通过这种先进的方法，我们能够更好地理解和利用大规模金融文本数据，为金融市场的稳定和发展做出贡献。


## 问题描述
#### FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
在金融领域进行情感分析是一项具有挑战性的任务，这主要是因为两个原因：<br>
一是金融文本中使用了大量的专业术语和特有的语言表达，使得通用的情感分析模型难以有效适应；<br>
二是缺乏大量标注数据，使得训练精确的情感分析模型变得困难，因为标注金融文本片段需要耗费高昂的专业成本。<br>
针对这些问题，FinBERT模型通过使用预训练的语言模型来捕捉文本的上下文语义信息，显著提高了模型在金融文本情感分析任务中的表现。<br>
但是尽管FinBERT模型已在金融情感分析任务中取得显著成绩，但仍存在一些不足之处。<br>
首先，FinBERT模型虽能有效捕捉上下文语义信息，但在提取文本中的关键信息方面仍有待加强。<br>
其次，现有模型在抵御对抗性攻击方面的鲁棒性不足，容易受到微小扰动的影响，从而导致分类结果的不准确。<br>
基于这些现存问题，我们提出了FinBERT-RCNN-ATTACK模型，旨在通过结合RCNN结构提高关键信息的提取能力，并引入对抗训练来增强模型的抗干扰性。<br>
本研究的主要目标是验证通过进一步预训练和微调预训练语言模型，能否显著提高金融领域情感分析的准确性。我们的实验将集中在如何通过增强模型的关键信息提取能力和鲁棒性，来解决FinBERT在金融文本情感分析中遇到的挑战。


## 实验方法
详细介绍用于实验的方法、算法、实验设计等。

## 实验评价


### 数据集介绍
数据集名称：Sentiment Analysis for Financial News
我们小组选取1个公开的英文数据集对提出的模型和其他现有模型进行实验，划分80%（3876条）作为训练数据，20%（970条）作为测试数据。该数据集包含从零售投资者视角出发的金融新闻标题的情感标注，用于研究和分析金融新闻对市场参与者情绪的影响，尤其关注新闻标题所蕴含的情绪倾向。通过对新闻标题的情感分析，可以帮助金融分析师和投资者更好地理解市场动态，预测市场趋势。
数据集包括两个字段：“情感”（Sentiment）和“新闻标题”（News Headline）。情感分类包括负面（negative）、中性（neutral）和正面（positive），这使得研究者可以直接利用这些数据进行情感分析，探索不同新闻标题背后的情感色彩。


### 评估指标
实验使用精确率( Precision) 、召回率 ( Recall) 和F1 分数(F1-Score)作为衡量模型分类性能的标准，计算公式如下所示。

$$
\text{Precision} = \frac{TP}{TP + FP}
$$

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

$$
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$


其中，TP( True Positive) 表示被正确预测的正例 。即 该数据的真实值为正例，预测值也为正例的情况；FP (False Positive)表示被错误预测的正例 。即该数据的 真实值为 反 例，但 被 错 误 预 测 成 了 正 例 的 情 况；FN (False Negative) 表示被错误预测的反例 。即该数据 的真实值为正例，但被错误预测成了反例的情况。

### 实验环境
描述实验的软硬件环境，包括使用的硬件配置、软件版本等信息。

### 对比实验
为了验证提出的模型在金融领域情感分析上的效果，本节对以下模型进行了对比实验(见图x和图x)。 BiLSTM : BiLSTM 是该领域的基线模型，是在LSTM(文献引用)的基础上进行改进和扩展的；TextCNN：文献（文献引用）使用 TextCNN 处理情感分类任务，具有速度快，准确率高的特征；BERT_CNN：在 BERT 模型下游引入CNN 提取词级特征；BERT_wwm：文献[24] 等针对金融领域文本，基于 BERT 提出全词覆盖与特征增强的预训练模型，提高了金融文本情感分类的精度；Fin⁃BERT：针对金融领域的NLP任务提出的预训练模型，可以更好地捕获语言知识和语义信息；Our_Model：小组提出的模型。


表x展示了各个模型在数据集上的实验结果。可以看出，该文提出的模型在 Precision , Recall 以及 F1-score 上均优于其他模型。

对比实验
| Model | Precision| F1-score| Recall
|:-:|:-:|:-:|:-:|
|BiLSTM|74.90%|74.71%|74.95%
|BERT-CNN|75.22%|75.11%|75.15%
|BERT-wwm|7.92%|12.36%|28.14%
|FinBERT|78.62%|77.55%|78.45%
|Our Model|85.65%|85.65%|85.77%


![Local Image](图片\对比实验.png "Local Image Title")<br>
首先，与BiLSTM模型相比，我们提出的模型在精确度、召回率和F1值方面均有显著提高。具体来看，精确度从74.90%提升到85.65%，召回率从74.95%提升到85.77%，而F1值提高了近11百分点，从74.71%提高到85.65%。这一显著的改进主要得益于预训练模型提供的上下文嵌入的增强，这有助于模型更好地理解和处理金融领域的复杂语义。
其次，与BERT-CNN和BERT-wwm相比，我们的模型在三个性能指标上均显示出较大幅度的提升。特别是与BERT-wwm相比，精确度从7.92%提升到85.65%，召回率从28.14%提升到85.77%，而F1值从12.36%提升到85.65%。这种显著的提升归因于FinBERT的预训练过程中包括大量金融专业语料的使用，使得模型在金融领域的任务处理上更为精准和有效。
相比于FinBERT模型，我们的模型在每个评估指标上均显示出了约8百分点左右的提升。这不仅是因为模型能够从金融语料中提取更关键的文本深层情感信息，而且通过在嵌入层加入扰动，增强了模型对新数据的泛化能力和对噪声的鲁棒性。
这些结果强调了在设计深度学习模型时考虑特定领域的语料预训练的重要性，以及进一步通过对抗训练增强模型鲁棒性的有效性。通过这种方式，我们的模型不仅在标准的性能指标上有所提升，更重要的是在实际应用中表现出更好的稳定性和可靠性。










### 消融实验
为了考察模型中各个模块的有效性，设置了模型中不同结构的消融实验（见图x和图x） , 模型具体细节如下：FinBERT：金融领域的预训练模型；FinBERT_RCNN：预训练模型下游引入RCNN模型提取关键信息；FinBERT_对抗训练：预训练模型引入对抗训练；Our_Model：该文提出的模型。
本节进行了消融实验，用来分析各模块的性能，结果记录在表x。通过消融实验发现模型的每个模块在提高性能方面都起着关键作用。

消融实验
| Model | Precision| F1-score| Recall|
|:-:|:-:|:-:|:-:|
|FindBERT-RCNN|84.64%|84.57%|84.54%|
|FindBERT-Attack|80.92%|79.36%|80.25%|
|FinBERT|78.62%|77.55%|78.45%|
|Our Model|86.65%|86.12%|86.51%|



![Local Image](图片\消融实验.png "Local Image Title")<br>



首先，FinBERT–RCNN模型在处理后的金融文本数据中展现了卓越的性能。通过采用FinBERT作为语言模型来处理上下文联系和语义信息，并结合RCNN来提取关键信息进行情感分类，模型在所有三个主要性能指标上均实现了显著提升。具体来看，精确度从FinBERT的78.62%提升到84.64%，召回率从78.45%提升到84.54%，而F1分数也从77.55%提升到84.57%，显示了RCNN模块在捕捉情感分类中关键特征方面的有效性。
其次，将对抗训练技术引入到FinBERT模型中，形成了FindBERT-Attack模型。此技术增强了模型对抗线性扰动攻击的能力，进一步提升了模型的鲁棒性和泛化性。相较于未经过对抗训练的FinBERT模型，FindBERT-Attack模型在精确度上从78.62%略微提升到80.92%，召回率从78.45%提升到80.25%，F1分数也从77.55%提升到79.36%。虽然提升幅度不如RCNN模型那般显著，这表明对抗训练在提升模型鲁棒性方面的作用更为微妙，但仍然有效。
最后，通过结合FinBERT的语义特征处理和RCNN的关键信息提取，并在模型中使用损失函数的梯度创建扰动，我们开发了Our Model。这一模型不仅保持了高水平的精确度和召回率，分别达到了86.65%和86.51%，而且在F1分数上也达到了86.12%，这一切都证明了模型设计的高效性和优越性。相比于原始的FinBERT模型，Our Model在精确度、召回率和F1分数上均有超过8百分点的全面提升，充分展现了整合多种技术后模型性能的显著增强。<br>

之后，我们小组又对Our Model进行了模型优化，特别是引入额外的卷积层和对抗训练策略，新模型（NEW_Model）在金融文本情感分析任务上表现出了显著的性能提升。
|   Model   | Precision | F1-score | Recall |
| :-------: | :-------: | :------: | :----: |
| NEW_Model |  92.17%   |  91.83%  | 92.04% |

精确度从原有模型的86.65%提高到92.17%，F1分数从86.12%提高到91.83%，召回率也从86.51%提升至92.04%。这些结果不仅显示了额外卷积层在深入提取文本特征方面的有效性，也突显了对抗训练在增强模型鲁棒性方面的重要作用。整体上，NEW_Model的表现超越了原始FinBERT模型，在所有主要性能指标上均实现了超过5百分点的提升，有效证明了结合深层特征学习与鲁棒性增强技术的设计策略的优越性。


## 相关工作
存在的局限性和潜在的改进方向
1. 语境敏感性和语言的歧义性：
尽管FinBERT和RCNN模型改进了情感分析，但它们可能仍然难以处理金融语言固有的歧义性和特定语境下的含义。
改进方向： 实施更复杂的语境感知训练策略和更深入的语义分析可能有所帮助。采用根据文本周围语境变化的动态词嵌入技术，可以为金融术语提供更细致的解释。
2. 适应金融语言快速变化的能力：
金融语言由于监管变化、市场转移和新金融产品的出现而迅速演变。静态模型可能无法迅速适应这些变化。
改进方向： 持续学习框架能够实时或几乎实时地更新模型的理解，随着新数据的可用性增强适应性。
3. 对标记数据的依赖：
这两种方法仍然显著依赖于标记数据集进行训练，这在金融等专业领域既昂贵又耗时。
改进方向： 增加使用无监督或半监督学习方法可以减少对标记数据的依赖。采用自我训练或师生学习模型，其中模型迭代标记未标记数据并重新训练自己，可能是有益的。
4. 模型复杂性和效率：
像BERT这样的模型在训练和推理时需要大量的计算资源，这在时间敏感的金融环境中可能是不切实际的。
改进方向： 通过剪枝、量化和知识蒸馏优化模型架构，可以在不显著损失性能的情况下减少模型大小和计算需求。
5. 跨不同金融语境的泛化能力：
模型性能可能在不同类型的金融文本（如新闻与报告）之间显著不同。
改进方向： 开发针对不同类型金融文件的专门子模型，或引入元学习方法，其中模型学习如何适应各种金融语境，可能会提高泛化能力。


## 未来展望
1. 整合到实时分析系统：
将这些模型实施在实时金融新闻和数据分析系统中，可能为市场情绪提供即时见解，帮助交易员和分析师做出更快的决策。
1. 增强特征工程：
探索更复杂的特征工程技术，能够捕捉金融语言的更高层次语义和句法特征，可能导致更健壮的模型。
1. 跨语言和跨域适应性：
扩展模型以理解多种语言并适应全球不同的金融市场，可能显著增加它们的实用性。
通过解决这些限制并探索所建议的改进，金融情感分析模型的下一代可能会实现更高的准确性、更好的泛化能力和更快的处理时间，使其更适合实际的金融应用。

## 参考文献
从原论文的参考文献里找一点出来。

## 附录
### 分工
详细描述每位团队成员的具体分工。

### 项目进度
展示项目的进度计划和实际完成情况。